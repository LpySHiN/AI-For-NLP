{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Why we need machine learning methods instead of creating a complicated formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "    \n",
    "    1、机器学习算法更具有一般性，复杂的公式算法只能基于特定场景解决问题；\n",
    "    \n",
    "    2、机器学习算法可以基于数据解决未知的问题，复杂的公式算法只能解决已存在的问题；\n",
    "    \n",
    "    3、机器学习算法coding更容易，复杂的公式算法coding较复杂。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Wha't's the disadvantages of the 1st Random Choosen methods in our course?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "    1、随机选择k、b，收敛速度较慢。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Is the 2nd method supervised direction better than 1st one? What's the disadvantages of the 2nd supversied directin method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "    \n",
    "    1、第二种监督方向的算法要优于第一种随机选择的算法；\n",
    "    \n",
    "    2、监督方向的算法中方向选择仍具有不确定性，算法在调整方向上花费了太多时间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Why do we use Derivative / Gredient to fit a target function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "    1、梯度和导数是函数变化速度的表征；\n",
    "    \n",
    "    2、我们需要得到最小的损失值，就是找函数的最小值，即导数为0的点；\n",
    "    \n",
    "    3、当我们求得导数为k后，0-k即为趋向最小值的变化方向的导数值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. In the words 'Gredient Descent', what's the Gredient and what's the Descent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "    1、Gredient，梯度表示损失函数对于不同自变量的偏导数，即反应自变量在某点的变化趋势；\n",
    "    \n",
    "    2、Descent，下降表示让损失函数值下降为最小值，即选取梯度的反方向为步进点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. What's the advantages of the 3rd gradient descent method compared to the previous methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "    1、参数调整的每一步，都是趋向于最小值进行的变更，确保了效率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Using the simple words to describe: What's the machine leanring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "    \n",
    "    1、机器学习的本质是优化。让机器通过损失函数和训练集，计算出函数的最优参数。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
